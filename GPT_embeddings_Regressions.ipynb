{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20021835-ba94-4d43-8e6b-e9ecb9f80739",
   "metadata": {},
   "source": [
    "# GPT Embeddings Regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecc0ffe-2910-4e35-b4bc-023ea1e4f2e4",
   "metadata": {},
   "source": [
    "### All the Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "933e60f6-ee3f-476a-b5ba-2b6ac39347f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes df and extracts labels for each companies\n",
    "def return_label(df,end_year):\n",
    "    return_dict={}\n",
    "    companies=pd.DataFrame(df[str(end_year)].dropna())\n",
    "    \n",
    "    for cik, label in companies.iterrows():\n",
    "        return_dict[cik]=label[str(end_year)]\n",
    "        \n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46e7f6dc-91a6-48b4-8857-6ab4ac6e884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts regressors and target\n",
    "from tqdm import tqdm\n",
    "def get_xy(corpus,labels):\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    for ix in tqdm(labels.keys()):\n",
    "        if corpus.get(str(ix),\"\"):\n",
    "            X.append(corpus[str(ix)])\n",
    "            Y.append(labels[ix])\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5cc0cdb-0338-413c-99b4-f741ef43bf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for training models\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "def do_train_10f(corpus, year):\n",
    "    labels = return_label(rev_df, year)\n",
    "    X, Y = get_xy(corpus, labels)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    not_nan_map = ~np.isnan(X)\n",
    "    map_ = np.array([False if np.isnan(i).any() else True for i in X])\n",
    "\n",
    "    X = X[map_]\n",
    "    Y = Y[map_]\n",
    "\n",
    "    # Initialize lists to store performance metrics for each fold\n",
    "    lr_train_accs, lr_test_accs, svc_train_accs, svc_test_accs = [], [], [], []\n",
    "    lr_prs, svc_prs = [], []\n",
    "    lr_recals, svc_recals = [], []\n",
    "    lr_f1s, svc_f1s = [], []\n",
    "    ovr_aurocs, ovo_aurocs = [], []\n",
    "\n",
    "    # Create a 10-fold stratified cross-validation splitter\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_indices, test_indices in skf.split(X, Y):\n",
    "        x_train, x_test = X[train_indices], X[test_indices]\n",
    "        y_train, y_test = Y[train_indices], Y[test_indices]\n",
    "        \n",
    "        for test_year in range(year, 2022):\n",
    "            labels = return_label(rev_df, year)\n",
    "            X, Y = get_xy(corpus, labels)\n",
    "\n",
    "        # Train-test split within the fold (0.1 test size)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.1, stratify=y_train)\n",
    "\n",
    "        # Logistic Regression\n",
    "        lr = LogisticRegression(n_jobs=-1, max_iter=1000)\n",
    "        lr.fit(x_train, y_train)\n",
    "\n",
    "        lr_train_acc = lr.score(x_train, y_train)\n",
    "        lr_test_acc = lr.score(x_test, y_test)\n",
    "\n",
    "        lr_pr = precision_score(y_test, lr.predict(x_test), average=\"weighted\", zero_division=0)\n",
    "        lr_rec = recall_score(y_test, lr.predict(x_test), average=\"weighted\", zero_division=0)\n",
    "        lr_f1 = precision_recall_fscore_support(y_test, lr.predict(x_test), average=\"weighted\", zero_division=0)\n",
    "\n",
    "        ovr_auroc = roc_auc_score(y_test, lr.predict_proba(x_test), multi_class=\"ovr\", average=\"weighted\")\n",
    "        ovo_auroc = roc_auc_score(y_test, lr.predict_proba(x_test), multi_class=\"ovo\", average=\"weighted\")\n",
    "\n",
    "        # Linear SVC\n",
    "        l_svc = LinearSVC(dual=False)\n",
    "        l_svc.fit(x_train, y_train)\n",
    "\n",
    "        svc_train_acc = l_svc.score(x_train, y_train)\n",
    "        svc_test_acc = l_svc.score(x_test, y_test)\n",
    "\n",
    "        svc_pr = precision_score(y_test, l_svc.predict(x_test), average=\"weighted\", zero_division=0)\n",
    "        svc_rec = recall_score(y_test, l_svc.predict(x_test), average=\"weighted\", zero_division=0)\n",
    "        svc_f1 = precision_recall_fscore_support(y_test, l_svc.predict(x_test), average=\"weighted\", zero_division=0)\n",
    "\n",
    "        # Append performance metrics to lists\n",
    "        lr_train_accs.append(lr_train_acc)\n",
    "        lr_test_accs.append(lr_test_acc)\n",
    "        svc_train_accs.append(svc_train_acc)\n",
    "        svc_test_accs.append(svc_test_acc)\n",
    "        lr_prs.append(lr_pr)\n",
    "        lr_recals.append(lr_rec)\n",
    "        lr_f1s.append(lr_f1)\n",
    "        ovr_aurocs.append(ovr_auroc)\n",
    "        ovo_aurocs.append(ovo_auroc)\n",
    "        svc_prs.append(svc_pr)\n",
    "        svc_recals.append(svc_rec)\n",
    "        svc_f1s.append(svc_f1)\n",
    "\n",
    "    # Calculate and return the mean values of the performance metrics\n",
    "    return lr_train_accs, lr_test_accs, svc_train_accs, svc_test_accs, lr_prs, lr_recals, lr_f1s, svc_prs, svc_recals, svc_f1s, ovr_aurocs, ovo_aurocs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ce69d5-824e-4180-8dd9-48f2df0b5293",
   "metadata": {},
   "source": [
    "### Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69ee938a-ea7e-4563-80b8-3298f61c449a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 3650/3650 [00:00<00:00, 939445.85it/s]\n",
      "\n",
      "100%|██████████| 3650/3650 [00:00<00:00, 924357.54it/s]\n",
      "\n",
      "100%|██████████| 3650/3650 [00:00<00:00, 1008910.61it/s]\n",
      "\n",
      "100%|██████████| 3650/3650 [00:00<00:00, 1021908.39it/s]\n",
      "\n",
      "100%|██████████| 3650/3650 [00:00<00:00, 1018983.60it/s]\n",
      "\n",
      "100%|██████████| 3650/3650 [00:00<00:00, 1015805.83it/s]\n",
      "\n",
      "100%|██████████| 3650/3650 [00:00<00:00, 1017426.04it/s]\n",
      "\n",
      "100%|██████████| 3650/3650 [00:00<00:00, 1011309.92it/s]\n",
      "\n",
      "100%|██████████| 3650/3650 [00:00<00:00, 964177.45it/s]\n",
      "\n",
      "100%|██████████| 3650/3650 [00:00<00:00, 1012045.32it/s]\n",
      "\n",
      "100%|██████████| 3650/3650 [00:00<00:00, 1014930.36it/s]\n",
      "  0%|          | 0/10 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m performance_dict\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr_train_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr_test_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvc_train_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvc_test_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr_precision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr_recall\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr_f1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvc_precision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvc_recall\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvc_f1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOVO_auroc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOVR_auroc\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mint\u001b[39m(year)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2023\u001b[39m):\n\u001b[0;32m---> 13\u001b[0m     performance_dict[i]\u001b[38;5;241m=\u001b[39m\u001b[43mdo_train_10f\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_corpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m main_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m performance_dict\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mdo_train_10f\u001b[0;34m(corpus, year)\u001b[0m\n\u001b[1;32m     29\u001b[0m skf \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_indices, test_indices \u001b[38;5;129;01min\u001b[39;00m skf\u001b[38;5;241m.\u001b[39msplit(X, Y):\n\u001b[0;32m---> 32\u001b[0m     x_train, x_test \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_indices\u001b[49m\u001b[43m]\u001b[49m, X[test_indices]\n\u001b[1;32m     33\u001b[0m     y_train, y_test \u001b[38;5;241m=\u001b[39m Y[train_indices], Y[test_indices]\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m test_year \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(year, \u001b[38;5;241m2022\u001b[39m):\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "main_dict = {}\n",
    "for year in tqdm(range(2011, 2021)):\n",
    "    # pickle file for k-10 filings\n",
    "    base_corpus=pickle.load(open(f\"GPT/future/{year}_future_documents_embd.pkl\",\"rb\"))\n",
    "\n",
    "    # labels csv file\n",
    "    rev_df=pd.read_csv(f\"labels/{year}.csv\",index_col=1)\n",
    "\n",
    "    performance_dict={'columns': [\"lr_train_acc\", \"lr_test_acc\", \"svc_train_acc\", \"svc_test_acc\", \"lr_precision\", \"lr_recall\", \"lr_f1\", \"svc_precision\", \"svc_recall\", \"svc_f1\", \"OVO_auroc\", \"OVR_auroc\"]}\n",
    "    for i in range(int(year)+1,2023):\n",
    "        performance_dict[i]=do_train_10f(base_corpus,i)\n",
    "    main_dict[f\"base_{year}\"] = performance_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdb9068-0660-4da0-a1b6-cafc2088bc81",
   "metadata": {},
   "source": [
    "### Saving the results into a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffee0dc5-4f30-454b-8d63-14d125a17493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Create a dictionary\n",
    "my_dict = main_dict\n",
    "\n",
    "# Specify the filename for the pickle file\n",
    "pickle_filename = 'gpt_future.pkl'\n",
    "\n",
    "# Open the file in binary write mode and use pickle.dump to save the dictionary\n",
    "with open(pickle_filename, 'wb') as pickle_file:\n",
    "    pickle.dump(my_dict, pickle_file)\n",
    "\n",
    "print(f'Dictionary has been pickled and saved to {pickle_filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2683d39-f0c5-4751-b7d8-11db3c6e2f27",
   "metadata": {},
   "source": [
    "### Training future models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e48bc2-cf81-48e5-b803-fb5e8bbbcc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "main_dict = {}\n",
    "for year in tqdm(range(2011, 2021)):\n",
    "    # pickle file for k-10 filings\n",
    "    base_corpus=pickle.load(open(f\"GPT/base/{year}_base_documents_embd.pkl\",\"rb\"))\n",
    "\n",
    "    # labels csv file\n",
    "    rev_df=pd.read_csv(f\"labels/{year}.csv\",index_col=1)\n",
    "\n",
    "    performance_dict={'columns': [\"lr_train_acc\", \"lr_test_acc\", \"svc_train_acc\", \"svc_test_acc\", \"lr_precision\", \"lr_recall\", \"lr_f1\", \"svc_precision\", \"svc_recall\", \"svc_f1\", \"OVO_auroc\", \"OVR_auroc\"]}\n",
    "    for i in range(int(year)+1,2023):\n",
    "        performance_dict[i]=do_train_10f(base_corpus,i)\n",
    "    main_dict[f\"base_{year}\"] = performance_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b81064-e1be-4199-9308-a2e95f92ef1f",
   "metadata": {},
   "source": [
    "### Saving the results into a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11a0d57-d1a4-458a-8e5b-ebf4e4882e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Create a dictionary\n",
    "my_dict = main_dict\n",
    "\n",
    "# Specify the filename for the pickle file\n",
    "pickle_filename = 'gpt_base.pkl'\n",
    "\n",
    "# Open the file in binary write mode and use pickle.dump to save the dictionary\n",
    "with open(pickle_filename, 'wb') as pickle_file:\n",
    "    pickle.dump(my_dict, pickle_file)\n",
    "\n",
    "print(f'Dictionary has been pickled and saved to {pickle_filename}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
