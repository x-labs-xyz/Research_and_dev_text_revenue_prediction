{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20021835-ba94-4d43-8e6b-e9ecb9f80739",
   "metadata": {},
   "source": [
    "# TFIDF Regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bcb5ef-59bb-4bff-8a28-d0316e9d49d6",
   "metadata": {},
   "source": [
    "### Functions in use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "933e60f6-ee3f-476a-b5ba-2b6ac39347f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes df and extracts labels for each companies\n",
    "def return_label(df,end_year):\n",
    "    return_dict={}\n",
    "    companies=pd.DataFrame(df[str(end_year)].dropna())\n",
    "    \n",
    "    for cik, label in companies.iterrows():\n",
    "        return_dict[cik]=label[str(end_year)]\n",
    "        \n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46e7f6dc-91a6-48b4-8857-6ab4ac6e884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts regressors and target\n",
    "from tqdm import tqdm\n",
    "def get_xy(corpus,labels):\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    for ix in tqdm(labels.keys()):\n",
    "        if corpus.get(str(ix),\"\"):\n",
    "            X.append(corpus[str(ix)])\n",
    "            Y.append(labels[ix])\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5cc0cdb-0338-413c-99b4-f741ef43bf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for training models\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "def do_train_10f(corpus, year):\n",
    "    labels = return_label(rev_df, year)\n",
    "    X, Y = get_xy(corpus, labels)\n",
    "    \n",
    "    # Train tf-idf vectors on the train-set\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "    X = [\" \".join(i) for i in X]\n",
    "    X = vectorizer.fit_transform(X)  # X remains a sparse matrix\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    # Initialize lists to store performance metrics for each fold\n",
    "    lr_train_accs, lr_test_accs, svc_train_accs, svc_test_accs = [], [], [], []\n",
    "    lr_prs, svc_prs = [], []\n",
    "    lr_recals, svc_recals = [], []\n",
    "    lr_f1s, svc_f1s = [], []\n",
    "    ovr_aurocs, ovo_aurocs = [], []\n",
    "\n",
    "    # Create a 10-fold stratified cross-validation splitter\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_indices, test_indices in skf.split(X, Y):\n",
    "        x_train, x_test = X[train_indices], X[test_indices]\n",
    "        y_train, y_test = Y[train_indices], Y[test_indices]\n",
    "\n",
    "        # Train-test split within the fold (0.1 test size)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.1, stratify=y_train)\n",
    "\n",
    "        # Logistic Regression\n",
    "        lr = LogisticRegression(n_jobs=-1, max_iter=1000)\n",
    "        lr.fit(x_train, y_train)\n",
    "\n",
    "        lr_train_acc = lr.score(x_train, y_train)\n",
    "        lr_test_acc = lr.score(x_test, y_test)\n",
    "\n",
    "        lr_pr = precision_score(y_test, lr.predict(x_test), average=\"weighted\", zero_division=0)\n",
    "        lr_rec = recall_score(y_test, lr.predict(x_test), average=\"weighted\", zero_division=0)\n",
    "        lr_f1 = precision_recall_fscore_support(y_test, lr.predict(x_test), average=\"weighted\", zero_division=0)\n",
    "\n",
    "        ovr_auroc = roc_auc_score(y_test, lr.predict_proba(x_test), multi_class=\"ovr\", average=\"weighted\")\n",
    "        ovo_auroc = roc_auc_score(y_test, lr.predict_proba(x_test), multi_class=\"ovo\", average=\"weighted\")\n",
    "\n",
    "        # Linear SVC\n",
    "        l_svc = LinearSVC(dual=False)\n",
    "        l_svc.fit(x_train, y_train)\n",
    "\n",
    "        svc_train_acc = l_svc.score(x_train, y_train)\n",
    "        svc_test_acc = l_svc.score(x_test, y_test)\n",
    "\n",
    "        svc_pr = precision_score(y_test, l_svc.predict(x_test), average=\"weighted\", zero_division=0)\n",
    "        svc_rec = recall_score(y_test, l_svc.predict(x_test), average=\"weighted\", zero_division=0)\n",
    "        svc_f1 = precision_recall_fscore_support(y_test, l_svc.predict(x_test), average=\"weighted\", zero_division=0)\n",
    "\n",
    "        # Append performance metrics to lists\n",
    "        lr_train_accs.append(lr_train_acc)\n",
    "        lr_test_accs.append(lr_test_acc)\n",
    "        svc_train_accs.append(svc_train_acc)\n",
    "        svc_test_accs.append(svc_test_acc)\n",
    "        lr_prs.append(lr_pr)\n",
    "        lr_recals.append(lr_rec)\n",
    "        lr_f1s.append(lr_f1)\n",
    "        ovr_aurocs.append(ovr_auroc)\n",
    "        ovo_aurocs.append(ovo_auroc)\n",
    "        svc_prs.append(svc_pr)\n",
    "        svc_recals.append(svc_rec)\n",
    "        svc_f1s.append(svc_f1)\n",
    "\n",
    "    # Calculate and return the mean values of the performance metrics\n",
    "    return lr_train_accs, lr_test_accs, svc_train_accs, svc_test_accs, lr_prs, lr_recals, lr_f1s, svc_prs, svc_recals, svc_f1s, ovr_aurocs, ovo_aurocs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722b13ff-4c8c-44bb-b8cc-ebe30ea1694b",
   "metadata": {},
   "source": [
    "### Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ee938a-ea7e-4563-80b8-3298f61c449a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 3650/3650 [00:00<00:00, 846046.40it/s]\n",
      "\n",
      "100%|██████████| 3673/3673 [00:00<00:00, 360788.73it/s]\n",
      "\n",
      "100%|██████████| 3638/3638 [00:00<00:00, 869798.66it/s]\n",
      "\n",
      "100%|██████████| 3664/3664 [00:00<00:00, 871988.76it/s]\n",
      "\n",
      "100%|██████████| 3682/3682 [00:00<00:00, 859879.03it/s]\n",
      "\n",
      "100%|██████████| 3675/3675 [00:00<00:00, 812506.84it/s]\n",
      "\n",
      "100%|██████████| 3653/3653 [00:00<00:00, 729956.77it/s]\n",
      "\n",
      "100%|██████████| 3701/3701 [00:00<00:00, 820287.42it/s]\n",
      "\n",
      "100%|██████████| 3610/3610 [00:00<00:00, 794200.76it/s]\n",
      "\n",
      "100%|██████████| 3681/3681 [00:00<00:00, 681282.90it/s]\n",
      "\n",
      "100%|██████████| 3519/3519 [00:00<00:00, 716632.15it/s]\n",
      " 10%|█         | 1/10 [04:50<43:36, 290.77s/it]\n",
      "100%|██████████| 3865/3865 [00:00<00:00, 817415.54it/s]\n",
      "\n",
      "100%|██████████| 3799/3799 [00:00<00:00, 734293.13it/s]\n",
      "\n",
      "100%|██████████| 3831/3831 [00:00<00:00, 792678.14it/s]\n",
      "\n",
      "100%|██████████| 3870/3870 [00:00<00:00, 871280.54it/s]\n",
      "\n",
      "100%|██████████| 3857/3857 [00:00<00:00, 742867.73it/s]\n",
      "\n",
      "100%|██████████| 3842/3842 [00:00<00:00, 774736.34it/s]\n",
      "\n",
      "100%|██████████| 3898/3898 [00:00<00:00, 741166.73it/s]\n",
      "\n",
      "100%|██████████| 3794/3794 [00:00<00:00, 806466.11it/s]\n",
      "\n",
      "100%|██████████| 3864/3864 [00:00<00:00, 869043.42it/s]\n",
      "\n",
      "100%|██████████| 3680/3680 [00:00<00:00, 803824.53it/s]\n",
      " 20%|██        | 2/10 [09:31<37:59, 284.89s/it]\n",
      "100%|██████████| 3930/3930 [00:00<00:00, 833516.12it/s]\n",
      "\n",
      "100%|██████████| 3941/3941 [00:00<00:00, 830974.87it/s]\n",
      "\n",
      "100%|██████████| 3975/3975 [00:00<00:00, 772369.05it/s]\n",
      "\n",
      "100%|██████████| 3992/3992 [00:00<00:00, 758764.74it/s]\n",
      "\n",
      "100%|██████████| 3984/3984 [00:00<00:00, 830480.95it/s]\n",
      "\n",
      "100%|██████████| 4024/4024 [00:00<00:00, 757909.17it/s]\n",
      "\n",
      "100%|██████████| 3915/3915 [00:00<00:00, 760288.00it/s]\n",
      "\n",
      "100%|██████████| 4011/4011 [00:00<00:00, 763656.53it/s]\n",
      "\n",
      "100%|██████████| 3838/3838 [00:00<00:00, 814209.64it/s]\n",
      " 30%|███       | 3/10 [14:04<32:37, 279.59s/it]\n",
      "100%|██████████| 4071/4071 [00:00<00:00, 819102.54it/s]\n",
      "\n",
      "100%|██████████| 4079/4079 [00:00<00:00, 805412.20it/s]\n",
      "\n",
      "100%|██████████| 4087/4087 [00:00<00:00, 754860.21it/s]\n",
      "\n",
      "100%|██████████| 4077/4077 [00:00<00:00, 745333.10it/s]\n",
      "\n",
      "100%|██████████| 4152/4152 [00:00<00:00, 832445.04it/s]\n",
      "\n",
      "100%|██████████| 4067/4067 [00:00<00:00, 858146.41it/s]\n",
      "\n",
      "100%|██████████| 4127/4127 [00:00<00:00, 783394.85it/s]\n",
      "\n",
      "100%|██████████| 3904/3904 [00:00<00:00, 798408.64it/s]\n",
      " 40%|████      | 4/10 [18:22<27:05, 270.94s/it]\n",
      "100%|██████████| 4331/4331 [00:00<00:00, 877646.66it/s]\n",
      "\n",
      "100%|██████████| 4288/4288 [00:00<00:00, 793837.20it/s]\n",
      "\n",
      "100%|██████████| 4316/4316 [00:00<00:00, 723959.85it/s]\n",
      "\n",
      "100%|██████████| 4363/4363 [00:00<00:00, 812455.53it/s]\n",
      "\n",
      "100%|██████████| 4252/4252 [00:00<00:00, 818644.97it/s]\n",
      "\n",
      "100%|██████████| 4330/4330 [00:00<00:00, 819222.17it/s]\n",
      "\n",
      "100%|██████████| 4104/4104 [00:00<00:00, 852782.94it/s]\n",
      " 50%|█████     | 5/10 [22:41<22:12, 266.53s/it]\n",
      "100%|██████████| 4503/4503 [00:00<00:00, 800531.98it/s]\n",
      "\n",
      "100%|██████████| 4474/4474 [00:00<00:00, 752418.45it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "main_dict = {}\n",
    "\n",
    "for year in tqdm(range(2011, 2021)):\n",
    "    year = str(year)\n",
    "    # pickle file for k-10 filings\n",
    "    base_corpus=pickle.load(open(f\"TFIDF/future/{year}_future_corpus.pkl\",\"rb\"))\n",
    "\n",
    "    # labels csv file\n",
    "    rev_df=pd.read_csv(f\"labels/{year}.csv\",index_col=1)\n",
    "\n",
    "    performance_dict={'columns': [\"lr_train_acc\", \"lr_test_acc\", \"svc_train_acc\", \"svc_test_acc\", \"lr_precision\", \"lr_recall\", \"lr_f1\", \"svc_precision\", \"svc_recall\", \"svc_f1\", \"OVO_auroc\", \"OVR_auroc\"]}\n",
    "    for i in range(int(year)+1,2023):\n",
    "        i = str(i)\n",
    "        performance_dict[i]=do_train_10f(base_corpus,i)\n",
    "    main_dict[f\"base_{year}\"] = performance_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9059a328-78ce-4c3d-ada8-afe685cde012",
   "metadata": {},
   "source": [
    "### Saving the results into a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9db1581-9e87-4cfb-9c42-6df35e5772ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Create a dictionary\n",
    "my_dict = main_dict\n",
    "\n",
    "# Specify the filename for the pickle file\n",
    "pickle_filename = 'tfidf_future.pkl'\n",
    "\n",
    "# Open the file in binary write mode and use pickle.dump to save the dictionary\n",
    "with open(pickle_filename, 'wb') as pickle_file:\n",
    "    pickle.dump(my_dict, pickle_file)\n",
    "\n",
    "print(f'Dictionary has been pickled and saved to {pickle_filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c919f31b-e2db-4d1d-a73c-c6f96ccd7e6a",
   "metadata": {},
   "source": [
    "### Training future models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a443ebb-2b3a-47b0-94cc-fccddac5fc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "main_dict = {}\n",
    "\n",
    "for year in tqdm(range(2011, 2021)):\n",
    "    year = str(year)\n",
    "    # pickle file for k-10 filings\n",
    "    base_corpus=pickle.load(open(f\"TFIDF/base/{year}_base_corpus.pkl\",\"rb\"))\n",
    "\n",
    "    # labels csv file\n",
    "    rev_df=pd.read_csv(f\"labels/{year}.csv\",index_col=1)\n",
    "\n",
    "    performance_dict={'columns': [\"lr_train_acc\", \"lr_test_acc\", \n",
    "                                  \"svc_train_acc\", \"svc_test_acc\", \n",
    "                                  \"lr_precision\", \"lr_recall\", \"lr_f1\", \n",
    "                                  \"svc_precision\", \"svc_recall\", \"svc_f1\", \n",
    "                                  \"OVO_auroc\", \"OVR_auroc\"]}\n",
    "    for i in range(int(year)+1,2023):\n",
    "        i = str(i)\n",
    "        performance_dict[i]=do_train_10f(base_corpus,i)\n",
    "    main_dict[f\"base_{year}\"] = performance_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73936df5-64c4-46f8-8807-9bdc0a12cc27",
   "metadata": {},
   "source": [
    "### Saving the results into a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7691baa6-c497-46c0-9889-e33ae265e45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Create a dictionary\n",
    "my_dict = main_dict\n",
    "\n",
    "# Specify the filename for the pickle file\n",
    "pickle_filename = 'tfidf_base.pkl'\n",
    "\n",
    "# Open the file in binary write mode and use pickle.dump to save the dictionary\n",
    "with open(pickle_filename, 'wb') as pickle_file:\n",
    "    pickle.dump(my_dict, pickle_file)\n",
    "\n",
    "print(f'Dictionary has been pickled and saved to {pickle_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9736cfde-134d-460f-a893-fae06be7fd50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
